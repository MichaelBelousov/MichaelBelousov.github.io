---
path: "/blog/my-thoughts-in-2024-on-generative-ai"
title: "My thoughts in 2024 on Generative AI"
date: "2024-09-02"
---

> I hope this article isn't just something you've read before. I am definitely drawing upon
> some existing ideas, but some of it is new to me, hopefully not out of ignorance.

Investing in the GenAI (LLM) hype is almost running out of steam here in August 2024,
most projects seem to just waste a lot of money and investors are becoming more conservative

Nonetheless, I think it's obvious, AI is here to stay for various fields, especially anywhere
we have large corpora of training data. Really, I'd wager the economic failure of GenAI is due to
the lack of reform in the software services market, and people just trying to apply
GenAI where the training data isn't ready. But that's not what I want to focus on.

As history should tell us, GenAI isn't going back in the box. I think any attempts to
limit what they can train on will not last long in the grand scheme of things.

I could be swayed, but for now I'm even the kind of intellectual property skeptic
that thinks scraping the internet for training data is mostly reasonable.
Making it illegal sounds very difficult to me, really equivalent to banning
general-purpose computers and free internet access (as governments and corporations
have been attempting to do for some time now of course).

## The GenAI future is prioritizing making training datasets

What we call generative AI seems to be a very useful statistical approximation
of any large datasets we can throw at it.

So far some of the main things we have large enough data stockpiles on seems to be:

- human-written texts in various languages
- human created digital art
- source-available programs in popular programming languages
- several kinds of historical sensor data

There are of course things that I think are too complex for AI to do a great job in
its current form. A good example would be videos of objects acting in a 3D space.
But I think there are more things that lack that inherent complexity and can be
replicated by AI.

However, I think the future will be a race to see who can gather enough data in a particular
process to reach useful AI in the corresponding field. The future will be about adding as
many sensors and as much telemetry as possible to everything, to gather enough data
for a trained GenAI to be useful.

It has actually already been the case, but it is now accelerating.

AI-automation will be a new phase of many fields&mdash; the phase at which
most existing processes are automatable. It will not replace true innovation,
which humans will still be ultimately responsible for.

Who knows what that will mean? The elimination of the practitioner class in those fields?&mdash;
leaving behind a tiny  minority of scientists pushing the boundaries for AI to follow?

And if not already, soon many of your tools will be watching you intensely,
making sure they have the data to replace you. In the current status quo,
we've allowed tech companies to do this for quite some time in consumption-oriented apps
(browsers, social media), so they could predict what we'd be willing to buy, and sell that
promise to advertisers. Now telemetry will also be added to productive applications
to build up training sets.

Not only will Photoshop be training on all your brush strokes, but soon even a surgeon's scalpel
will be tracking its precise location and angle and comparing it to scans and photos of
the body it's slicing through, to power future surgical robots.

Putting sensors everywhere and programming robots with AI trained on that sensor data
will concievably automate many delicate, currently human, processes like surgery and many
forms of previously creative manufacturing.

I wonder if it sounds dystopian just because it's such a stark change from our previous reality,
but it does sound daunting even when I'm not particularly against it. It even seems to already
be automating away some of what I have always considered creative and fun in my own craft.

## With great economic change comes...

There is already a battle raging on people's rights to not be trained upon.
I think in the long-run the economics of efficiency will win,
hastend by state competition probably.

So I am skeptical that existing attempts to block and illegalize training will hold
for very long.

AI may be hitting speed bumps, but I think it really will become an integral
next step for many industries, as digitizing has been over the last several decades.
It will be slower than we think, as each industry reaches its GenAI point after
carefully collecting training data.

But the change it will wreak may be so great, that I'm not sure
which structures and institutions of our societies will hold.
If we have any luck at all, the slowness of each industry working on generating its
necessary datasets may give our instutions the time to evolve.

Anyway, I think AI really does make the future quite uncertain.
